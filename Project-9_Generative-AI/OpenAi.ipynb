{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["[ OpenAI API Reference](https://platform.openai.com/docs/api-reference/introduction)"],"metadata":{"id":"cYlG8_tU6Vtp"}},{"cell_type":"code","source":["pip install openai"],"metadata":{"id":"aex9KbMJKi0k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690554347741,"user_tz":240,"elapsed":11929,"user":{"displayName":"Dr. Vincent Techo","userId":"13547138880704380104"}},"outputId":"d86faeb9-4c12-40b6-f32a-7bdb434afd9b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai\n","  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n","Installing collected packages: openai\n","Successfully installed openai-0.27.8\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Ws4uIjCUJxHa","executionInfo":{"status":"ok","timestamp":1690554349206,"user_tz":240,"elapsed":1472,"user":{"displayName":"Dr. Vincent Techo","userId":"13547138880704380104"}}},"outputs":[],"source":["import openai\n","import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt"]},{"cell_type":"code","source":["openai.api_key = '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'"],"metadata":{"id":"vPkXOcwxKmE7","executionInfo":{"status":"ok","timestamp":1690554349207,"user_tz":240,"elapsed":9,"user":{"displayName":"Dr. Vincent Techo","userId":"13547138880704380104"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def get_davinci_response(prompt, max_tokens, temp):\n","  response = openai.Completion.create(\n","      engine=\"text-davinci-003\",\n","      prompt=prompt,\n","      max_tokens=max_tokens,\n","      n=1,\n","      stop=None,\n","      temperature=temp,\n","      )\n","  return response.choices[0].text"],"metadata":{"id":"ucLKuyZqLApF","executionInfo":{"status":"ok","timestamp":1690554349207,"user_tz":240,"elapsed":7,"user":{"displayName":"Dr. Vincent Techo","userId":"13547138880704380104"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["get_davinci_response(\"create a name for a fire pokemon that eats embers\", 100,1.3)"],"metadata":{"id":"wbOX-F6gM9jd","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1690554349926,"user_tz":240,"elapsed":725,"user":{"displayName":"Dr. Vincent Techo","userId":"13547138880704380104"}},"outputId":"4f69f001-87f5-484d-f820-a244cbc542ee"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n\\nEmberBeast'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["def get_gpt_response(prompt,context, max_tokens,temp):\n","  response=openai.ChatCompletion.create(\n","      model=\"gpt-3.5-turbo\",\n","      messages= [\n","          {'role':'user','content':context},\n","          {'role': 'user','content':prompt}],\n","          max_tokens=max_tokens,\n","          n=1,\n","          stop=None,\n","          temperature=temp,\n","  )\n","  return response['choices'][0]['message']['content']\n","\n"],"metadata":{"id":"OPglubIdNXIA","executionInfo":{"status":"ok","timestamp":1690554349927,"user_tz":240,"elapsed":11,"user":{"displayName":"Dr. Vincent Techo","userId":"13547138880704380104"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["prompt=\"What is an ensemble?\""],"metadata":{"id":"MJMUOwWHRIUA","executionInfo":{"status":"ok","timestamp":1690554349927,"user_tz":240,"elapsed":7,"user":{"displayName":"Dr. Vincent Techo","userId":"13547138880704380104"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["context=\"python programming\"\n","print(context)"],"metadata":{"id":"RD-yN1cFRUK7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690554350151,"user_tz":240,"elapsed":5,"user":{"displayName":"Dr. Vincent Techo","userId":"13547138880704380104"}},"outputId":"0f2e7b07-614a-444c-edbd-43bf24169484"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["python programming\n"]}]},{"cell_type":"code","source":["prompt='How can I add context to text-davinci-003  responses'"],"metadata":{"id":"2EfyPjTmRjAo","executionInfo":{"status":"ok","timestamp":1690554350152,"user_tz":240,"elapsed":6,"user":{"displayName":"Dr. Vincent Techo","userId":"13547138880704380104"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["get_gpt_response(prompt,context,1000,0.2)"],"metadata":{"id":"Hq_9hawJRvLm","colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"status":"ok","timestamp":1690554362789,"user_tz":240,"elapsed":12642,"user":{"displayName":"Dr. Vincent Techo","userId":"13547138880704380104"}},"outputId":"b3d02f43-16bb-43f2-f0ed-74f59c418fa0"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'To add context to the responses generated by the text-davinci-003 model in Python, you can use the `openai.ChatCompletion.create()` method from the OpenAI API. This method allows you to have a dynamic conversation with the model by providing a series of messages as input.\\n\\nHere\\'s an example of how you can add context to the responses:\\n\\n```python\\nimport openai\\n\\n# Set up OpenAI API credentials\\nopenai.api_key = \\'YOUR_API_KEY\\'\\n\\n# Define the conversation history\\nconversation = [\\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\\n    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\\n    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\\n    {\"role\": \"user\", \"content\": \"Where was it played?\"}\\n]\\n\\n# Generate a response by providing the conversation history\\nresponse = openai.ChatCompletion.create(\\n    model=\"text-davinci-003\",\\n    messages=conversation,\\n    max_tokens=50\\n)\\n\\n# Get the assistant\\'s reply from the response\\nreply = response[\\'choices\\'][0][\\'message\\'][\\'content\\']\\nprint(reply)\\n```\\n\\nIn this example, the conversation history is stored in the `conversation` list. Each message in the conversation has a \"role\" (either \"system\", \"user\", or \"assistant\") and \"content\" (the actual text of the message).\\n\\nBy providing this conversation history to the `messages` parameter of the `openai.ChatCompletion.create()` method, you can generate a response that takes into account the context of the previous messages.\\n\\nNote that you can extend the conversation by simply adding more messages to the `conversation` list. The model will consider the entire conversation history when generating a response.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["prompt='write the code to add context to text-davinci-003 completions'"],"metadata":{"id":"BzN2RqPFR1ag","executionInfo":{"status":"ok","timestamp":1690554362790,"user_tz":240,"elapsed":11,"user":{"displayName":"Dr. Vincent Techo","userId":"13547138880704380104"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["print(get_gpt_response(prompt,context,1000,0.2))"],"metadata":{"id":"lm9udXg7TvLr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690554369210,"user_tz":240,"elapsed":6426,"user":{"displayName":"Dr. Vincent Techo","userId":"13547138880704380104"}},"outputId":"d5f413b4-0c89-4428-b7a6-595918bf56d5"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["To add context to text-davinci-003 completions in Python, you can make use of the OpenAI API. Here's an example code snippet:\n","\n","```python\n","import openai\n","\n","# Set up your OpenAI API credentials\n","openai.api_key = 'YOUR_API_KEY'\n","\n","# Define your prompt and context\n","prompt = \"Once upon a time\"\n","context = \" in a small village, there lived a young boy named Jack.\"\n","\n","# Generate completion using text-davinci-003 model\n","response = openai.Completion.create(\n","  engine=\"text-davinci-003\",\n","  prompt=prompt + context,\n","  max_tokens=100,\n","  temperature=0.7,\n","  n=1,\n","  stop=None\n",")\n","\n","# Extract the generated completion from the response\n","completion = response.choices[0].text.strip()\n","\n","# Print the generated completion\n","print(completion)\n","```\n","\n","In this code, you need to replace `'YOUR_API_KEY'` with your actual OpenAI API key. The `prompt` variable represents the initial text, and the `context` variable represents the additional context you want to add to the prompt. The `max_tokens` parameter specifies the maximum length of the generated completion. The `temperature` parameter controls the randomness of the output, and the `n` parameter determines the number of completions to generate. Finally, the generated completion is extracted from the API response and printed.\n","\n","Make sure you have the `openai` package installed (`pip install openai`) and an active OpenAI subscription to use the API.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"8dwvwihJT_8D","executionInfo":{"status":"ok","timestamp":1690554369211,"user_tz":240,"elapsed":20,"user":{"displayName":"Dr. Vincent Techo","userId":"13547138880704380104"}}},"execution_count":12,"outputs":[]}]}